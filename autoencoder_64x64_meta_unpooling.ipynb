{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   cluster     y     x          E   size\n",
      "0           0  004580_A   9.0  26.0   715232.0  108.0\n",
      "1           1  011701_G  15.0  17.0  1184202.0  179.0\n",
      "2           2  003882_A   3.0   3.0    31156.0    6.0\n",
      "3           3  009717_G   7.0  62.0  1423016.0  245.0\n",
      "4           4  005590_A  32.0  31.0  1014772.0  169.0\n",
      "   Unnamed: 0   cluster     y     x          E   size\n",
      "0           0  004580_A   9.0  26.0   715232.0  108.0\n",
      "1           1  011701_G  15.0  17.0  1184202.0  179.0\n",
      "2           2  003882_A   3.0   3.0    31156.0    6.0\n",
      "3           3  009717_G   7.0  62.0  1423016.0  245.0\n",
      "4           4  005590_A  32.0  31.0  1014772.0  169.0\n"
     ]
    }
   ],
   "source": [
    "meta_data = pd.read_csv('cluster_meta.csv')\n",
    "print(meta_data.head())\n",
    "\n",
    "def load_data(folder_path,meta_data):\n",
    "    data = []\n",
    "    for file in meta_data['cluster']:\n",
    "        file = file + '.csv'\n",
    "        file_path = os.path.join(folder_path,file)\n",
    "        cluster = pd.read_csv(file_path,header=None).values\n",
    "        cluster = cluster.flatten()\n",
    "        cluster = np.append(cluster, meta_data[meta_data['cluster'] == file[:-4]][['y', 'x', 'E', 'size']].values.flatten())\n",
    "        data.append(cluster)\n",
    "    combined_array = np.stack(data,axis=0)\n",
    "    print('shape of combined array: ')\n",
    "    print(combined_array.shape)\n",
    "    return combined_array\n",
    "\n",
    "\n",
    "meta_scaler = MinMaxScaler()\n",
    "meta_data_values = meta_scaler.fit_transform(meta_data[['y', 'x', 'E', 'size']])\n",
    "print(meta_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_pad_csvs(folder_path):\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    data_arrays = []\n",
    "    number_arrays = len(csv_files)\n",
    "    number_large = 0\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = pd.read_csv(file_path).values\n",
    "        data_arrays.append(data)\n",
    "    max_rows = max(array.shape[0] for array in data_arrays)\n",
    "    max_cols = max(array.shape[1] for array in data_arrays)\n",
    "    largest_array_index = max(range(len(data_arrays)), key=lambda i: data_arrays[i].shape[0] * data_arrays[i].shape[1])\n",
    "    print(f\"Index of the largest initial array: {largest_array_index}\")\n",
    "    padded_arrays = []\n",
    "    for array in data_arrays:\n",
    "        if array.shape[0] <= 64 and array.shape[1] <= 64:\n",
    "            padded_array = np.zeros((64, 64))\n",
    "            padded_array[:array.shape[0], :array.shape[1]] = array\n",
    "            padded_arrays.append(padded_array)\n",
    "            number_large += 1\n",
    "    print(f'Number of arrays that are smaller than 64x64: {number_large}, ({number_large/number_arrays*100:.2f}%)')\n",
    "    print(f'max rows: {max_rows}, max cols:{max_cols}')\n",
    "    combined_array = np.stack(padded_arrays, axis=0)\n",
    "    return combined_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined array: \n",
      "(3936, 4100)\n",
      "(3936, 4100)\n",
      "(3936, 4100)\n"
     ]
    }
   ],
   "source": [
    "class NumpyArrayDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data.astype(np.float32)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample  # Return only the sample and dummy label\n",
    "\n",
    "folder_path = 'clusters_colour_rotations_rescaled'\n",
    "combined_array = load_data(folder_path,meta_data)\n",
    "\n",
    "scalar = MinMaxScaler()\n",
    "combined_array = scalar.fit_transform(combined_array.reshape(-1, 1)).reshape(combined_array.shape)\n",
    "print(combined_array.shape)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "#meta_data_values = NumpyArrayDataset(meta_data_values, transform=transform)\n",
    "dataset = NumpyArrayDataset(combined_array, transform=transform)\n",
    "print(combined_array.shape)\n",
    "\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# print(meta_data_values.shape)\n",
    "\n",
    "\n",
    "# train_dataset, test_dataset, train_meta, test_meta = train_test_split(dataset, meta_data_values, test_size=0.2, random_state=42)\n",
    "# test_dataset = dataset\n",
    "\n",
    "# lazy, non-random split\n",
    "test_size = 0.2\n",
    "split_index = int(len(dataset) * (1 - test_size))\n",
    "train_dataset = dataset[:split_index]\n",
    "test_dataset = dataset[split_index:]\n",
    "train_meta = meta_data_values[:split_index]\n",
    "test_meta = meta_data_values[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3148, 4100])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "valid_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(train_loader.dataset[0].shape)\n",
    "\n",
    "#train_meta = DataLoader(train_meta, batch_size=32, shuffle=False)\n",
    "#test_meta = DataLoader(test_meta, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.613412e+07, 3.920000e+02, 2.240000e+02, 2.400000e+02,\n",
       "        1.840000e+02, 1.440000e+02, 1.760000e+02, 2.160000e+02,\n",
       "        1.760000e+02, 3.040000e+02, 1.680000e+02, 1.680000e+02,\n",
       "        2.240000e+02, 1.120000e+02, 1.120000e+02, 1.120000e+02,\n",
       "        6.400000e+01, 5.600000e+01, 1.600000e+01, 2.400000e+01,\n",
       "        4.000000e+01, 6.400000e+01, 4.000000e+01, 1.600000e+01,\n",
       "        8.000000e+00, 0.000000e+00, 2.400000e+01, 2.400000e+01,\n",
       "        8.000000e+00, 8.000000e+00, 8.000000e+00, 1.600000e+01,\n",
       "        8.000000e+00, 0.000000e+00, 8.000000e+00, 8.000000e+00,\n",
       "        8.000000e+00, 0.000000e+00, 0.000000e+00, 8.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 1.600000e+01,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 1.600000e+01,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 8.000000e+00, 8.000000e+00,\n",
       "        8.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 8.000000e+00, 0.000000e+00, 8.000000e+00]),\n",
       " array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "        0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "        0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "        0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "        0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "        0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "        0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "        0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "        0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "        0.99, 1.  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.hist(combined_array.flatten(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(combined_array[3929,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Var_Encoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section:\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=1, padding=1),  # 1x256x256 -> 32x128x128\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),  # 32x128x128 -> 64x64x64\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, return_indices=True)  # 64x64x64 -> 64x32x32\n",
    "        )\n",
    "        \n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=0)\n",
    " \n",
    "        # Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(65536+4, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "\n",
    "        ### Variational part\n",
    "        self.variational_mean = nn.Linear(encoded_space_dim, encoded_space_dim)\n",
    "        self.variational_var = nn.Linear(encoded_space_dim, encoded_space_dim)\n",
    "\n",
    "    def reparameterization(self, mean, var):  # Stolen from MNIST example, device must be understood\n",
    "        epsilon = torch.randn_like(var).cpu() \n",
    "        z = mean + var * epsilon\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        meta = x[-4:]\n",
    "        x = x[:-4].unflatten(0, (1, 1, 64, 64))\n",
    "        # print('pass to encoder:', x.shape)\n",
    "        x, indices = self.encoder_cnn(x)  # Capture indices from MaxPool2d\n",
    "        # print('encoder output:', x.shape, 'indices', indices.shape)\n",
    "        x = self.flatten(x)\n",
    "        # print('flattened:', x.shape, meta.shape)\n",
    "        y = torch.cat((x, meta), dim=0)\n",
    "        # print('concatenated:', y.shape)\n",
    "        x = self.encoder_lin(y)\n",
    "        # print('linear output:', x.shape)\n",
    "        mean = self.variational_mean(x)\n",
    "        log_var = self.variational_var(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var))\n",
    "        return z, mean, log_var, indices\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 65536),  # Update to match your encoder's output\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.unflatten = nn.Unflatten(dim = 1, unflattened_size=(64, 32, 32))\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.unpool = nn.MaxUnpool2d(2)\n",
    "        self.final_conv = nn.ConvTranspose2d(64, 1, 3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x, indices):\n",
    "        # print('test0', x.shape, indices.shape)\n",
    "        x = self.decoder_lin(x).reshape((1,65536))\n",
    "        # print('test1', x.shape)\n",
    "        x = self.unflatten(x)\n",
    "        # print('test2', x.shape)\n",
    "        x = self.decoder_conv(x)\n",
    "        # print('test3', x.shape)\n",
    "        # Here we assume the output size of the unpooling layer, which is the size of the maxpool input\n",
    "        # output_size = torch.Size([1, 64, 64, 64])\n",
    "        x = self.unpool(x, indices)#, output_size=output_size)\n",
    "        x = self.final_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print((train_loader.dataset[0][0]))\n",
    "# x = train_loader.dataset[0][0]\n",
    "# print(x.shape)\n",
    "# x = x[:-4].reshape((1,1,64,64))\n",
    "\n",
    "\n",
    "# # encoder:\n",
    "# A = nn.Conv2d(1, 32, 3, stride=1, padding=1)\n",
    "# B = nn.Conv2d(32, 64 , 3, stride=1, padding=1)\n",
    "# C = nn.MaxPool2d(2)\n",
    "\n",
    "# # flatten\n",
    "# D = nn.Flatten()\n",
    "\n",
    "# # linear\n",
    "# E = nn.Linear(65536, 128)\n",
    "# F = nn.Linear(128, 10)\n",
    "\n",
    "# print(f'original data: {x.shape}')\n",
    "\n",
    "# print('encoder:')\n",
    "\n",
    "# print(f'Conv1: {A(x).shape}')\n",
    "# print(f'Conv2: {B(A(x)).shape}')\n",
    "# print(f'MaxPool: {C(B(A(x))).shape}')\n",
    "# print(f'Flatten: {D(C(B(A(x)))).shape}')\n",
    "# print(f'Linear1: {E(D(C(B(A(x))))).shape}')\n",
    "# print(f'Linear2: {F(E(D(C(B(A(x)))))).shape}')\n",
    "\n",
    "\n",
    "\n",
    "# print('decoder:')\n",
    "\n",
    "\n",
    "# x = train_loader.dataset[0][0]\n",
    "# x = x[:-4].reshape((1,1,64,64))\n",
    "# x = F(E(D(C(B(A(x))))))\n",
    "# # decoder:\n",
    "# G = nn.Linear(10, 128)\n",
    "# H = nn.Linear(128, 65536)\n",
    "# I = nn.Unflatten(dim=1, \n",
    "#         unflattened_size=(64, 32, 32))\n",
    "# J = nn.ConvTranspose2d(64, 64, 3, stride=1,padding = 1)#, output_padding=0)\n",
    "# # K = nn.BatchNorm2d(64)\n",
    "# L = nn.ConvTranspose2d(64, 1, 3, stride=1, padding = 1)#, padding=1, output_padding=1)\n",
    "# # M = nn.BatchNorm2d(8)\n",
    "# # N = nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "# print(f'Linear1: {G(x).shape}')\n",
    "# print(f'Linear2: {H(G(x)).shape}')\n",
    "# print(f'Unflatten: {I(H(G(x))).shape}')\n",
    "# print(f'Conv1: {J(I(H(G(x)))).shape}')\n",
    "# print(f'BatchNorm: {K(J(I(H(G(x))))).shape}')\n",
    "# print(f'Conv2: {L(K(J(I(H(G(x)))))).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data: torch.Size([1, 1, 64, 64])\n",
      "encoder:\n",
      "Conv1: torch.Size([1, 32, 64, 64])\n",
      "Conv2: torch.Size([1, 64, 64, 64])\n",
      "MaxPool: torch.Size([1, 64, 32, 32])\n",
      "Flatten: torch.Size([1, 65536])\n",
      "Linear1: torch.Size([1, 128])\n",
      "Linear2: torch.Size([1, 10])\n",
      "decoder:\n",
      "Linear1: torch.Size([1, 128])\n",
      "Linear2: torch.Size([1, 65536])\n",
      "Unflatten: torch.Size([1, 64, 32, 32])\n",
      "Conv1: torch.Size([1, 64, 32, 32])\n",
      "MaxUnpool: torch.Size([1, 64, 64, 64])\n",
      "Conv2: torch.Size([1, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x = train_loader.dataset[0][0]\n",
    "x = x[:-4].reshape((1, 1, 64, 64))\n",
    "\n",
    "# Encoder:\n",
    "A = nn.Conv2d(1, 32, 3, stride=1, padding=1)\n",
    "B = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "C = nn.MaxPool2d(2, return_indices=True)  # Updated to return indices\n",
    "\n",
    "# Flatten\n",
    "D = nn.Flatten()\n",
    "\n",
    "# Linear\n",
    "E = nn.Linear(65536, 128)\n",
    "F = nn.Linear(128, 10)\n",
    "\n",
    "# Encoder forward pass\n",
    "conv1 = A(x)\n",
    "conv2 = B(conv1)\n",
    "maxpool, indices = C(conv2)  # Capture indices for unpooling\n",
    "# print(indices.shape)\n",
    "# print(indices)\n",
    "flattened = D(maxpool)\n",
    "linear1 = E(flattened)\n",
    "linear2 = F(linear1)\n",
    "\n",
    "print(f'original data: {x.shape}')\n",
    "\n",
    "print('encoder:')\n",
    "print(f'Conv1: {conv1.shape}')\n",
    "print(f'Conv2: {conv2.shape}')\n",
    "print(f'MaxPool: {maxpool.shape}')\n",
    "print(f'Flatten: {flattened.shape}')\n",
    "print(f'Linear1: {linear1.shape}')\n",
    "print(f'Linear2: {linear2.shape}')\n",
    "\n",
    "# Decoder:\n",
    "G = nn.Linear(10, 128)\n",
    "H = nn.Linear(128, 65536)\n",
    "I = nn.Unflatten(dim=1, unflattened_size=(64, 32, 32))\n",
    "J = nn.ConvTranspose2d(64, 64, 3, stride=1, padding=1)\n",
    "K = nn.MaxUnpool2d(2)\n",
    "L = nn.ConvTranspose2d(64, 1, 3, stride=1, padding=1)\n",
    "\n",
    "# Decoder forward pass\n",
    "x = linear2\n",
    "linear1 = G(x)\n",
    "linear2 = H(linear1)\n",
    "unflattened = I(linear2)\n",
    "conv1_trans = J(unflattened)\n",
    "unpool = K(conv1_trans, indices)  # Use indices here\n",
    "\n",
    "\n",
    "print('decoder:')\n",
    "print(f'Linear1: {linear1.shape}')\n",
    "print(f'Linear2: {linear2.shape}')\n",
    "print(f'Unflatten: {unflattened.shape}')\n",
    "print(f'Conv1: {conv1_trans.shape}')\n",
    "print(f'MaxUnpool: {unpool.shape}')\n",
    "\n",
    "conv2_trans = L(unpool)\n",
    "\n",
    "print(f'Conv2: {conv2_trans.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and training parameters:\n",
    "def loss_fn(recon_x, x, mean, log_var):\n",
    "    #MSE = nn.MSELoss()(recon_x, x) \n",
    "    BCE = nn.BCELoss(reduction='sum')(recon_x, x)\n",
    "    KLD = - 0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    #print(MSE, KLD)\n",
    "    lambda_= 1\n",
    "    return BCE + lambda_ * KLD\n",
    "\n",
    "#loss_fn = nn.MSELoss()\n",
    "\n",
    "lr = 0.01\n",
    "torch.manual_seed(42)\n",
    "\n",
    "d = 28\n",
    "encoder = Var_Encoder(encoded_space_dim=d)\n",
    "# var_encoder = Var_Encoder(encoded_space_dim=d)\n",
    "decoder = Decoder(encoded_space_dim=d)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "\n",
    "def train_epoch(encoder, decoder, dataloader, loss_fn, optimizer):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    for image_batch in dataloader.dataset[0]:\n",
    "        #encoded_data = encoder(image_batch)\n",
    "        # print('hi')\n",
    "        encoded_data,mean,var, indices = encoder(image_batch) #VAE\n",
    "        # print('hello')\n",
    "        decoded_data = decoder(encoded_data, indices)\n",
    "        #loss = loss_fn(decoded_data, image_batch[:-4].reshape(decoded_data.shape))\n",
    "        # print('no error so far')\n",
    "        # print(image_batch[:-4].reshape(decoded_data.shape))\n",
    "        loss = loss_fn(decoded_data, image_batch[:-4].reshape(decoded_data.shape),mean,var) #VAE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "    return np.mean(train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(encoder, decoder, dataloader, loss_fn):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        mean_out = []\n",
    "        var_out = []\n",
    "        for image_batch in dataloader.dataset[0]:\n",
    "            #encoded_data = encoder(image_batch)\n",
    "            encoded_data,mean,var, indices = var_encoder(image_batch) #VAE\n",
    "            decoded_data = decoder(encoded_data,indices)\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch[:-4].reshape(decoded_data.shape).cpu())\n",
    "            mean_out.append(mean.cpu())\n",
    "            var_out.append(var.cpu())\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label)\n",
    "        mean = torch.cat(mean_out) #VAE\n",
    "        var = torch.cat(var_out) #VAE\n",
    "        #val_loss = loss_fn(conc_out, conc_label)\n",
    "        val_loss = loss_fn(conc_out, conc_label,mean,var) #VAE\n",
    "    return val_loss.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_loss = {'train_loss': [], 'val_loss': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      3\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m test_epoch(encoder, decoder, test_loader, loss_fn)\n\u001b[0;32m      6\u001b[0m     elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[16], line 42\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(encoder, decoder, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     40\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     41\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 42\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(train_loss)\n",
      "File \u001b[1;32mc:\\Users\\Ambrusius\\Anaconda3\\envs\\appmlenv\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ambrusius\\Anaconda3\\envs\\appmlenv\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\Ambrusius\\Anaconda3\\envs\\appmlenv\\Lib\\site-packages\\torch\\optim\\adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    158\u001b[0m         group,\n\u001b[0;32m    159\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    164\u001b[0m         state_steps)\n\u001b[1;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Ambrusius\\Anaconda3\\envs\\appmlenv\\Lib\\site-packages\\torch\\optim\\adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ambrusius\\Anaconda3\\envs\\appmlenv\\Lib\\site-packages\\torch\\optim\\adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(encoder, decoder, train_loader, loss_fn, optim)\n",
    "    val_loss = test_epoch(encoder, decoder, test_loader, loss_fn)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if epoch != 0:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} \\t train loss: {train_loss:.2e} \\t Delta: {diz_loss['train_loss'][-1]-train_loss:.5e} \\t val loss: {val_loss:.5e} \\t Delta: {diz_loss['val_loss'][-1]-val_loss:.2e} \\t time: {elapsed_time}')\n",
    "    else:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} \\t train loss: {train_loss:.5e} \\t val loss: {val_loss:.5e} \\t time: {elapsed_time}')\n",
    "    print(f'Elapsed time: {elapsed_time}')\n",
    "    diz_loss['train_loss'].append(train_loss)\n",
    "    diz_loss['val_loss'].append(val_loss)\n",
    "    #plot_ae_outputs(encoder, decoder, n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[0;32m      2\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_yscale(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ax.set_xscale('log')\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "ax.plot(diz_loss['train_loss'], label='train loss')\n",
    "# ax.plot(diz_loss['val_loss'], label='val loss')\n",
    "ax.legend()\n",
    "# ax.set_xlim(0, 50)\n",
    "\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=28, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=1296, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(16, 9, 9))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(16, 16, kernel_size=(16, 16), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(16, 1, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumf = 0\n",
    "# for i in range(6400):\n",
    "#     img = test_dataset[i][0].unsqueeze(0).numpy()\n",
    "#     suming = np.sum(img)\n",
    "#     if suming>sumf:\n",
    "#         sumf = sumimg\n",
    "#         idx = i\n",
    "# print(i)\n",
    "# print(sumf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate model on radoom image\n",
    "img = test_dataset[0][3]\n",
    "with torch.no_grad():\n",
    "    rec_img = decoder(encoder(img))\n",
    "    rec_img = rec_img.squeeze().numpy()\n",
    "    img = img[:-4].squeeze().numpy().reshape(64,64)\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[0].set_title('Original image')\n",
    "    ax[1].imshow(rec_img, cmap='gray')\n",
    "    ax[1].set_title('Reconstructed image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    # Function to save the model\n",
    "    model_name = '64x64_MinMaxScaler'\n",
    "    def save_model(encoder, decoder, encoder_path=\"encoder.pth\", decoder_path=\"decoder.pth\"):\n",
    "        torch.save(encoder.state_dict(), encoder_path)\n",
    "        torch.save(decoder.state_dict(), decoder_path)\n",
    "        print(\"Models saved to {} and {}\".format(encoder_path, decoder_path))\n",
    "    enc = 'training_results/' + model_name + '/encoder.pth'\n",
    "    dec = 'training_results/' + model_name + '/decoder.pth'\n",
    "    save_model(encoder, decoder, encoder_path=enc, decoder_path=dec)\n",
    "    np.savetxt('training_results/' + model_name + '/train_loss.txt', diz_loss['train_loss'])\n",
    "    np.savetxt('training_results/' + model_name + '/val_loss.txt', diz_loss['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_initial_convolutions(encoder, num_filters=8, figsize=(15, 15)):\n",
    "    \"\"\"\n",
    "    Plots the initial convolutional filters of the encoder.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoder: The trained encoder model.\n",
    "    - num_filters: Number of filters to plot. Default is 16.\n",
    "    - figsize: Size of the plot. Default is (15, 15).\n",
    "    \"\"\"\n",
    "    # Extract the weights from the first convolutional layer\n",
    "    conv1_weights = encoder.encoder_cnn[0].weight.data.cpu().numpy()\n",
    "    \n",
    "    # Create a figure to plot the filters\n",
    "    fig, axes = plt.subplots(1, num_filters, figsize=figsize)\n",
    "    \n",
    "    for i in range(num_filters):\n",
    "        ax = axes[i]\n",
    "        # Get the filter\n",
    "        filt = conv1_weights[i, 0, :, :]\n",
    "        # Plot the filter\n",
    "        ax.imshow(filt, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Filter {i+1}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Usage example\n",
    "plot_initial_convolutions(encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the latent space\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
