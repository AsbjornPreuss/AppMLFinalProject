{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 18:51:50.299666: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-08 18:51:52.437966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, MinMaxScaler\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import DBSCAN\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add labels to meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_raw = [np.load('./labels/'+x) for x in os.listdir('./labels/') if x.endswith('.npy')]\n",
    "\n",
    "label_dict = {}\n",
    "value_array = []\n",
    "for values in labels_raw:\n",
    "    for value,ind in zip(values[0],values[1]):\n",
    "        value_array.append(value)\n",
    "        #print(value)\n",
    "        label_dict[value] = ind\n",
    "\n",
    "meta_data = pd.read_csv('cluster_meta.csv')\n",
    "file_index = meta_data['cluster'].values\n",
    "\n",
    "label_list = [label_dict[int(x[:-2])] for x in file_index]\n",
    "\n",
    "meta_data.insert(5,'label',label_list)\n",
    "\n",
    "meta_data.drop(meta_data[meta_data['label'] == 4].index)\n",
    "meta_data.drop(meta_data[meta_data['label'] == 0].index)\n",
    "meta_data['label'] = meta_data['label'] - 1\n",
    "\n",
    "meta_data = meta_data.to_csv('cluster_meta_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   cluster     y     x          E  label   size\n",
      "0           0  004580_A   9.0  26.0   715232.0      2  108.0\n",
      "1           1  011701_G  15.0  17.0  1184202.0      3  179.0\n",
      "2           2  003882_A   3.0   3.0    31156.0      0    6.0\n",
      "3           3  009717_G   7.0  62.0  1423016.0      2  245.0\n",
      "4           4  005590_A  32.0  31.0  1014772.0      2  169.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "meta_data = pd.read_csv('cluster_meta_labels.csv')\n",
    "print(meta_data.head())\n",
    "\n",
    "def load_data_with_label(folder_path, meta_data):\n",
    "    data = []\n",
    "    for file in meta_data['cluster']:\n",
    "        file = file + '.csv'\n",
    "        file_path = os.path.join(folder_path,file)\n",
    "        cluster = pd.read_csv(file_path,header=None).values\n",
    "        cluster = cluster.flatten()\n",
    "        # cluster = np.append(cluster, meta_data[meta_data['cluster'] == file[:-4]][['y', 'x', 'E', 'size']].values.flatten())\n",
    "        data.append(cluster)\n",
    "    combined_array = np.stack(data,axis=0)\n",
    "    print('shape of combined array: ')\n",
    "    print(combined_array.shape)\n",
    "    return combined_array, meta_data[['y', 'x', 'E', 'size']].values, meta_data['label'].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "meta_scaler = RobustScaler()\n",
    "meta_data_values = meta_scaler.fit_transform(meta_data[['y', 'x', 'E', 'size']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined array: \n",
      "(3936, 4096)\n"
     ]
    }
   ],
   "source": [
    "class NumpyArrayDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data.astype(np.float32)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample  # Return only the sample and dummy label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder_path = 'clusters_colour_rotations_rescaled'\n",
    "combined_array, meta_data_values, meta_data_labels = load_data_with_label(folder_path, meta_data)\n",
    "\n",
    "meta_data_labels = meta_data_labels.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normelize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3936, 4096)\n",
      "(3936, 4101)\n",
      "torch.Size([3148, 4101])\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "combined_array_scaled = scaler.fit_transform(np.log(combined_array))\n",
    "print(combined_array.shape)\n",
    "\n",
    "meta_scaler = QuantileTransformer()\n",
    "meta_data_values = meta_scaler.fit_transform(meta_data_values)\n",
    "\n",
    "combined_array_scaled = np.append(combined_array_scaled, meta_data_values, axis=1)\n",
    "\n",
    "combined_array_scaled = np.append(combined_array_scaled, meta_data_labels[:,None], axis=1)\n",
    "#print(combined_array_scaled.T[-5:])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "np.random.shuffle(combined_array_scaled)\n",
    "\n",
    "#meta_data_values = NumpyArrayDataset(meta_data_values, transform=transform)\n",
    "dataset = NumpyArrayDataset(combined_array_scaled, transform=transform)\n",
    "print(combined_array_scaled.shape)\n",
    "\n",
    "# lazy, non-random split\n",
    "test_size = 0.2\n",
    "split_index = int(len(dataset) * (1 - test_size))\n",
    "train_dataset = dataset[:split_index]\n",
    "test_dataset = dataset[split_index:]\n",
    "#train_meta = meta_data_values[:split_index]\n",
    "#test_meta = meta_data_values[split_index:]\n",
    "#train_labels = meta_data_labels[:split_index]\n",
    "#test_labels = meta_data_labels[split_index:]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "valid_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "print(train_loader.dataset[0].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chosse device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def create_torch_model_CNN(trial):\n",
    "    N_conv_layers = 2 #trial.suggest_int('N_conv_layers', 1, 3)\n",
    "    N_dense_layers = 22 #trial.suggest_int('N_dense_layers', 1, 3)\n",
    "    dropout_rate = 0.5 #trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    num_classes = 3\n",
    "    class torch_CNN(nn.Module):\n",
    "        def __init__(self, output_size):\n",
    "            super().__init__()\n",
    "\n",
    "            ### Convolutional section:\n",
    "            self.cnn_layer = nn.Sequential(\n",
    "                nn.Conv2d(1, 32, 3, stride=1, padding=1),  # 1x64x64 -> 32x64x64\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(32, 64, 3, stride=1, padding=1),  # 32x128x128 -> 64x64x64\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2)  # 64x64x64 -> 64x32x32\n",
    "            )\n",
    "\n",
    "            ### Flattening:\n",
    "            self.flatten = nn.Flatten(start_dim=0)\n",
    "\n",
    "            ### Linerar section\n",
    "            self.linerar_layer = nn.Sequential(\n",
    "                nn.Linear(65536, 128),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "            ### output layer\n",
    "            self.output_layer = nn.Sequential(\n",
    "                nn.Linear(128, output_size),\n",
    "                nn.Softmax()\n",
    "            )\n",
    "\n",
    "            ### dropout\n",
    "            self.dropout = nn.Dropout(dropout_rate, inplace=True)\n",
    "        \n",
    "        def create_CNN_layer(self, filters_in, filters_out):\n",
    "            #filters_out = 32\n",
    "            filter_size = 3\n",
    "            stride_cnn = 1\n",
    "            padding = 1\n",
    "            pool_size = 2\n",
    "            pool_stride = 1\n",
    "            cnn_layer = nn.Sequential(\n",
    "                nn.Conv2d(filters_in, filters_out, filter_size, stride=stride_cnn, padding=padding),  # 1x256x256 -> 32x128x128\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(pool_size, stride=pool_stride)  # 64x64x64 -> 64x32x32\n",
    "            )\n",
    "            return cnn_layer, filters_out\n",
    "        \n",
    "        def create_liniar_layer(self, input_size, output_size):\n",
    "            liniar_layer = nn.Sequential(\n",
    "                nn.Linear(input_size, output_size),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "            return liniar_layer, output_size\n",
    "        \n",
    "        def create_output_layer(self, input_size, output_size):\n",
    "            output_layer = nn.Sequential(\n",
    "                nn.Linear(input_size, output_size),\n",
    "                nn.Softmax()\n",
    "            )\n",
    "            return output_layer\n",
    "        \n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            \n",
    "            meta = x[-5:-1]\n",
    "            label = x[-1]\n",
    "            x = x[:-5].unflatten(0, (1, 1, 64, 64))\n",
    "\n",
    "            cnn_layer0, filters_out0 = self.create_CNN_layer(1, 32)\n",
    "            x = cnn_layer0(x)\n",
    "            cnn_layer1, filters_out1 = self.create_CNN_layer(filters_out0, 64)\n",
    "            x = cnn_layer1(x)\n",
    "\n",
    "            x = self.flatten(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            liniar_layer0_input_size = x.shape[0]\n",
    "            #print(liniar_layer0_input_size)\n",
    "\n",
    "            liniar_layer0, output_size0 = self.create_liniar_layer(liniar_layer0_input_size, 128)\n",
    "            x = liniar_layer0(x)\n",
    "            liniar_layer1, output_size1 = self.create_liniar_layer(output_size0, 64)\n",
    "            x = liniar_layer1(x)\n",
    "            y = torch.cat((x, meta), dim=0)\n",
    "            output_layer = self.create_output_layer(output_size1 + 4, num_classes) # incorperates the meta data in the final layer\n",
    "            x = output_layer(y)\n",
    "           \n",
    "            return x, label.type(torch.cuda.ByteTensor)\n",
    "    return torch_CNN(num_classes).to(device)\n",
    "\n",
    "\n",
    "def create_tf_optimizer(trial):\n",
    "    # We optimize the choice of optimizers as well as their parameters.\n",
    "    kwargs = {}\n",
    "    \n",
    "    optimizer_selected = \"Adam\"\n",
    "    \n",
    "    kwargs[\"learning_rate\"] = trial.suggest_float(\"adam_learning_rate\", 1e-7, 1e-1, log=True)\n",
    "\n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    return optimizer\n",
    "\n",
    "def objective(trial, X_train, Y_train, X_test, Y_test):\n",
    "    # Build model and optimizer.\n",
    "    model = create_tf_model_CNN(trial)\n",
    "    optimizer = create_tf_optimizer(trial)\n",
    "    model.compile(optimizer, loss=CategoricalCrossentropy())\n",
    "    # Fit the model to the data\n",
    "    model.fit(x=X_train, y = Y_train, epochs=30, validation_data=(X_test, Y_test), verbose=0)\n",
    "    # Find the accuracy\n",
    "    cce = CategoricalCrossentropy()\n",
    "    accuracy = cce(Y_test, model(X_test))\n",
    "    # Return accuracy\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(output, target):\n",
    "    return F.cross_entropy(output, target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(dataset_train, model, optimizer, loss_function):\n",
    "    running_loss = 0\n",
    "    dataset_train = dataset_train.to(device)\n",
    "    print(type(dataset_train))\n",
    "    \n",
    "    for batch in dataset_train:\n",
    "        optimizer.zero_grad()\n",
    "        output, label_train = model(batch)\n",
    "        print(label_train.type(), output.type())\n",
    "        loss = loss_function(output, label_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataset_train)\n",
    "\n",
    "def validate_epoch(dataset_val, model, loss_function):\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset_val:\n",
    "            output, label_val = model(batch)\n",
    "            loss = loss_function(output, label_val)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(dataset_val)\n",
    "\n",
    "def train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(dataset_train, model, optimizer, loss_function)\n",
    "        valid_loss = validate_epoch(dataset_val, model, loss_function)\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        end_time = time.time()\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Duration: {end_time - start_time:.2f} sec\")\n",
    "    return train_losses, valid_losses\n",
    "\n",
    "def plot_losses(train_losses, valid_losses):\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(valid_losses, label='Valid Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unflatten: Provided sizes [1, 1, 64, 64] don't multiply up to the size of dim 0 (3143) in the input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_func\u001b[39m(model, dataset):\n\u001b[1;32m     12\u001b[0m     model(dataset)\n\u001b[0;32m---> 14\u001b[0m output, label \u001b[38;5;241m=\u001b[39m test_func(model, dataset_train)\n",
      "Cell \u001b[0;32mIn[50], line 12\u001b[0m, in \u001b[0;36mtest_func\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_func\u001b[39m(model, dataset):\n\u001b[0;32m---> 12\u001b[0m     model(dataset)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 71\u001b[0m, in \u001b[0;36mcreate_torch_model_CNN.<locals>.torch_CNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m meta \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     70\u001b[0m label \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 71\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m0\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n\u001b[1;32m     73\u001b[0m cnn_layer0, filters_out0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_CNN_layer(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     74\u001b[0m x \u001b[38;5;241m=\u001b[39m cnn_layer0(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:1307\u001b[0m, in \u001b[0;36mTensor.unflatten\u001b[0;34m(self, dim, sizes)\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39munflatten(dim, sizes, names)\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39munflatten(dim, sizes)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unflatten: Provided sizes [1, 1, 64, 64] don't multiply up to the size of dim 0 (3143) in the input tensor"
     ]
    }
   ],
   "source": [
    "model = create_torch_model_CNN(3)\n",
    "model.to(device)\n",
    "dataset_train = train_loader.dataset[0]\n",
    "dataset_train.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "torch.manual_seed(42)\n",
    "peram_to_optimize = model.parameters()\n",
    "optimizer = optim.Adam(peram_to_optimize, lr=learning_rate)\n",
    "model.train()\n",
    "def test_func(model, dataset):\n",
    "    model(dataset)\n",
    "\n",
    "output, label = test_func(model, dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 30\u001b[0m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     24\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 30\u001b[0m train_losses, valid_losses \u001b[38;5;241m=\u001b[39m train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\n\u001b[1;32m     32\u001b[0m plot_losses(train_losses, valid_losses)\n",
      "Cell \u001b[0;32mIn[35], line 163\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    162\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(dataset_train, model, optimizer, loss_function)\n\u001b[1;32m    164\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m validate_epoch(dataset_val, model, loss_function)\n\u001b[1;32m    165\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[35], line 139\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(dataset_train, model, optimizer, loss_function)\u001b[0m\n\u001b[1;32m    137\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(batch))\n\u001b[0;32m--> 139\u001b[0m output, label_train \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(label_train\u001b[38;5;241m.\u001b[39mtype(), output\u001b[38;5;241m.\u001b[39mtype())\n\u001b[1;32m    141\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(output, label_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 74\u001b[0m, in \u001b[0;36mcreate_torch_model_CNN.<locals>.torch_CNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m0\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n\u001b[1;32m     73\u001b[0m cnn_layer0, filters_out0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_CNN_layer(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m x \u001b[38;5;241m=\u001b[39m cnn_layer0(x)\n\u001b[1;32m     75\u001b[0m cnn_layer1, filters_out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_CNN_layer(filters_out0, \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     76\u001b[0m x \u001b[38;5;241m=\u001b[39m cnn_layer1(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "model = create_torch_model_CNN(3).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "dataset_train = train_loader.dataset[0]\n",
    "dataset_val = valid_loader.dataset[0]\n",
    "\n",
    "\n",
    "dataset_train = dataset_train.to(device)\n",
    "dataset_val = dataset_val.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "torch.manual_seed(42)\n",
    "peram_to_optimize = model.parameters()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(peram_to_optimize, lr=learning_rate)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_losses, valid_losses = train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\n",
    "\n",
    "plot_losses(train_losses, valid_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
