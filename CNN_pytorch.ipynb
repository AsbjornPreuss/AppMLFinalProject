{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_rescaled_csv(folder_path):\n",
    "    # List all CSV files in the given folder\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    csv_files_sorted = np.sort(np.array(csv_files))\n",
    "    #print(csv_files_sorted)\n",
    "    # Initialize an empty list to store the data arrays\n",
    "    data_arrays = []\n",
    "\n",
    "    indecies = np.zeros_like(csv_files_sorted, dtype=int)\n",
    "    for i in range(len(csv_files_sorted)):\n",
    "        indecies[i] = int(csv_files_sorted[i][:-6])\n",
    "        #print(type(indecies[i]))\n",
    "    #print(csv_files_sorted, indecies)\n",
    "        \n",
    "    \n",
    "    # Iterate over the CSV files and read them into numpy arrays\n",
    "    for file in csv_files_sorted:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = pd.read_csv(file_path, header=None).values\n",
    "        data_arrays.append(data)\n",
    "\n",
    "    return data_arrays, indecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 119\n"
     ]
    }
   ],
   "source": [
    "data_raw, index = import_rescaled_csv('clusters_colour_rotations_rescaled/')\n",
    "\n",
    "labels_raw = [np.load('./labels/'+x) for x in os.listdir('./labels/') if x.endswith('.npy')]\n",
    "print(len(labels_raw[8][0]), len(labels_raw[8][1]))\n",
    "\n",
    "\n",
    "label_dict = {}\n",
    "value_array = []\n",
    "for values in labels_raw:\n",
    "    for value,ind in zip(values[0],values[1]):\n",
    "        value_array.append(value)\n",
    "        #print(value)\n",
    "        label_dict[value] = ind\n",
    "\n",
    "label = [label_dict[i_] for i_ in index]\n",
    "label = np.array(label, dtype=int)\n",
    "\n",
    "data_raw = np.array(data_raw)\n",
    "data_raw = data_raw[(label != 4) * (label != 0)]\n",
    "label = label[(label != 4) * (label != 0)] - 1\n",
    "\n",
    "\n",
    "\n",
    "train_images, testval_images, train_labels, testval_labels = train_test_split(data_raw, label, test_size=0.2, random_state=13052020)\n",
    "\n",
    "# further split testval set into specific test and validation set\n",
    "# the test set is NOT used during any part but inference\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(testval_images, testval_labels, test_size=0.5, random_state=13052020)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normelize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nnum_classes = 3 # number of classes\\ntrain_labels = keras.utils.to_categorical(train_labels, num_classes)\\nval_labels = keras.utils.to_categorical(val_labels, num_classes)\\ntest_labels = keras.utils.to_categorical(test_labels, num_classes)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "\n",
    "# save for scaling test data\n",
    "mu_train = np.mean(train_images)\n",
    "sigma_train = np.std(train_images)\n",
    "\n",
    "\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "scaler.fit(train_images.reshape(-1, 1))\n",
    "train_images = scaler.transform(train_images.reshape(-1, 1)).reshape(train_images.shape)\n",
    "val_images = scaler.transform(val_images.reshape(-1, 1)).reshape(val_images.shape)\n",
    "#test_images = scaler.transform(test_images.reshape(-1, 1)).reshape(test_images.shape)\n",
    "\n",
    "plt.hist(train_images.flatten(), bins=100, range=(0.01, 1))\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# adapt to format required by tensorflow; Using channels_last --> (n_samples, img_rows, img_cols, n_channels)\n",
    "img_rows, img_cols = 64, 64 # input image dimensions\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "val_images = val_images.reshape(val_images.shape[0], img_rows, img_cols, 1)\n",
    "#test_images = val_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# convert class vectors to binary class matrices - one hot encoding\n",
    "\"\"\"\n",
    "num_classes = 3 # number of classes\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "val_labels = keras.utils.to_categorical(val_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chosse device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_model_CNN(trial):\n",
    "    N_conv_layers = trial.suggest_int('N_conv_layers', 1, 3)\n",
    "    N_dense_layers = trial.suggest_int('N_dense_layers', 1, 3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    model = Sequential()  # Network type is Sequential\n",
    "    for i in range(N_conv_layers):\n",
    "        model.add(Conv2D(filters=2**trial.suggest_int('conv_filter_exp'+str(i), 3, 7),\n",
    "                         kernel_size=trial.suggest_int('conv_kernel_size'+str(i), 2, 5),\n",
    "                         strides=1,\n",
    "                         padding='same',\n",
    "                         activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2, strides=None))\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Flatten())\n",
    "    for i in range(N_dense_layers - 1):\n",
    "        model.add(Dense(units=2**trial.suggest_int('dense_units_exp'+str(i), 3, 5), activation='relu'))\n",
    "    model.add(Dense(units=num_classes, activation='softmax'))\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_torch_model_CNN(trial):\n",
    "    N_conv_layers = trial.suggest_int('N_conv_layers', 1, 3)\n",
    "    N_dense_layers = trial.suggest_int('N_dense_layers', 1, 3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    dropout_rate = 0.5\n",
    "    num_classes = 3\n",
    "    class torch_CNN(nn.Module):\n",
    "        def __init__(self, output_size):\n",
    "            super().__init()\n",
    "\n",
    "            ### Convolutional section:\n",
    "            self.cnn_layer = nn.Sequential(\n",
    "                nn.Conv2d(1, 32, 3, stride=1, padding=1),  # 1x64x64 -> 32x64x64\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(32, 64, 3, stride=1, padding=1),  # 32x128x128 -> 64x64x64\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2)  # 64x64x64 -> 64x32x32\n",
    "            )\n",
    "\n",
    "            ### Flattening:\n",
    "            self.flatten = nn.Flatten(start_dim=0)\n",
    "\n",
    "            ### Linerar section\n",
    "            self.linerar_layer = nn.Sequential(\n",
    "                nn.Linear(65536, 128),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "            ### output layer\n",
    "            self.output_layer = nn.Sequential(\n",
    "                nn.linear(128, output_size),\n",
    "                nn.Softmax()\n",
    "            )\n",
    "\n",
    "            ### dropout\n",
    "            self.dropout = nn.Dropout(dropout_rate, inplace=True)\n",
    "        \n",
    "        def create_CNN_layer(self, filters_in, filters_out):\n",
    "            #filters_out = 32\n",
    "            filter_size = 3\n",
    "            stride_cnn = 1\n",
    "            padding = 1\n",
    "            pool_size = 2\n",
    "            pool_stride = 1\n",
    "            cnn_layer = nn.Sequential(\n",
    "                nn.Conv2d(filters_in, filters_out, filter_size, stride=stride_cnn, padding=padding),  # 1x256x256 -> 32x128x128\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(pool_size, stride=pool_stride)  # 64x64x64 -> 64x32x32\n",
    "            )\n",
    "            return cnn_layer, filters_out\n",
    "        \n",
    "        def create_liniar_layer(self, input_size, output_size):\n",
    "            liniar_layer = nn.Sequential(\n",
    "                nn.Linear(input_size, output_size),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "            return liniar_layer, output_size\n",
    "        \n",
    "        def create_output_layer(self, input_size, output_size):\n",
    "            output_layer = nn.Sequential(\n",
    "                nn.linear(input_size, output_size),\n",
    "                nn.Softmax()\n",
    "            )\n",
    "            return output_layer\n",
    "        \n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "\n",
    "            cnn_layer0, filters_out0 = self.create_CNN_layer(1, 32)\n",
    "            x = cnn_layer0(x)\n",
    "            cnn_layer1, filters_out1 = self.create_CNN_layer(filters_out0, 64)\n",
    "            x = cnn_layer1(x)\n",
    "\n",
    "            x = self.flatten(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            liniar_layer0, output_size0 = self.create_liniar_layer(65536, 128)\n",
    "            x = liniar_layer0(x)\n",
    "            liniar_layer1, output_size1 = self.create_liniar_layer(output_size0, 64)\n",
    "            x = liniar_layer1(x)\n",
    "\n",
    "            output_layer = self.create_output_layer(output_size1, num_classes)\n",
    "            x = output_layer(x)\n",
    "           \n",
    "            return x\n",
    "    return torch_CNN(num_classes).to(device)\n",
    "\n",
    "\n",
    "def create_tf_optimizer(trial):\n",
    "    # We optimize the choice of optimizers as well as their parameters.\n",
    "    kwargs = {}\n",
    "    \n",
    "    optimizer_selected = \"Adam\"\n",
    "    \n",
    "    kwargs[\"learning_rate\"] = trial.suggest_float(\"adam_learning_rate\", 1e-7, 1e-1, log=True)\n",
    "\n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    return optimizer\n",
    "\n",
    "def objective(trial, X_train, Y_train, X_test, Y_test):\n",
    "    # Build model and optimizer.\n",
    "    model = create_tf_model_CNN(trial)\n",
    "    optimizer = create_tf_optimizer(trial)\n",
    "    model.compile(optimizer, loss=CategoricalCrossentropy())\n",
    "    # Fit the model to the data\n",
    "    model.fit(x=X_train, y = Y_train, epochs=30, validation_data=(X_test, Y_test), verbose=0)\n",
    "    # Find the accuracy\n",
    "    cce = CategoricalCrossentropy()\n",
    "    accuracy = cce(Y_test, model(X_test))\n",
    "    # Return accuracy\n",
    "    return accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
