{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, MinMaxScaler\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import DBSCAN\n",
    "import time\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add labels to meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_raw = [np.load('./labels/'+x) for x in os.listdir('./labels/') if x.endswith('.npy')]\n",
    "\n",
    "label_dict = {}\n",
    "value_array = []\n",
    "for values in labels_raw:\n",
    "    for value,ind in zip(values[0],values[1]):\n",
    "        value_array.append(value)\n",
    "        #print(value)\n",
    "        label_dict[value] = ind\n",
    "\n",
    "meta_data = pd.read_csv('cluster_meta.csv')\n",
    "file_index = meta_data['cluster'].values\n",
    "\n",
    "label_list = [label_dict[int(x[:-2])] for x in file_index]\n",
    "\n",
    "meta_data.insert(6,'label',label_list)\n",
    "\n",
    "meta_data = meta_data.drop(meta_data[meta_data['label'] == 4].index)\n",
    "meta_data = meta_data.drop(meta_data[meta_data['label'] == 0].index)\n",
    "meta_data['label'] = meta_data['label'] - 1\n",
    "\n",
    "\n",
    "\n",
    "meta_data = meta_data.to_csv('cluster_meta_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   cluster     y     x          E   size  label\n",
      "0           0  004580_A   9.0  26.0   715232.0  108.0      2\n",
      "1           2  003882_A   3.0   3.0    31156.0    6.0      0\n",
      "2           3  009717_G   7.0  62.0  1423016.0  245.0      2\n",
      "3           4  005590_A  32.0  31.0  1014772.0  169.0      2\n",
      "4           5  008859_G  13.0   9.0   397825.0   63.0      2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "meta_data = pd.read_csv('cluster_meta_labels.csv')\n",
    "print(meta_data.head())\n",
    "\n",
    "def load_data_with_label(folder_path, meta_data):\n",
    "    data = []\n",
    "    for file in meta_data['cluster']:\n",
    "        file = file + '.csv'\n",
    "        file_path = os.path.join(folder_path,file)\n",
    "        cluster = pd.read_csv(file_path,header=None).values\n",
    "        cluster = cluster.flatten()\n",
    "        # cluster = np.append(cluster, meta_data[meta_data['cluster'] == file[:-4]][['y', 'x', 'E', 'size']].values.flatten())\n",
    "        data.append(cluster)\n",
    "    combined_array = np.stack(data,axis=0)\n",
    "    print('shape of combined array: ')\n",
    "    print(combined_array.shape)\n",
    "    return combined_array, meta_data[['y', 'x', 'E', 'size']].values, meta_data['label'].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "meta_scaler = RobustScaler()\n",
    "meta_data_values = meta_scaler.fit_transform(meta_data[['y', 'x', 'E', 'size']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined array: \n",
      "(3112, 4096)\n"
     ]
    }
   ],
   "source": [
    "class NumpyArrayDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data.astype(np.float32)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample  # Return only the sample and dummy label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder_path = 'clusters_colour_rotations_rescaled'\n",
    "combined_array, meta_data_values, meta_data_labels = load_data_with_label(folder_path, meta_data)\n",
    "\n",
    "meta_data_labels = meta_data_labels.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normelize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3112, 4096)\n",
      "(3112, 4101)\n",
      "torch.Size([2489, 4101])\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "combined_array_scaled = scaler.fit_transform(np.log(combined_array))\n",
    "print(combined_array.shape)\n",
    "\n",
    "meta_scaler = QuantileTransformer()\n",
    "meta_data_values = meta_scaler.fit_transform(meta_data_values)\n",
    "\n",
    "combined_array_scaled = np.append(combined_array_scaled, meta_data_values, axis=1)\n",
    "\n",
    "combined_array_scaled = np.append(combined_array_scaled, meta_data_labels[:,None], axis=1)\n",
    "#print(combined_array_scaled.T[-5:])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "np.random.shuffle(combined_array_scaled)\n",
    "\n",
    "#meta_data_values = NumpyArrayDataset(meta_data_values, transform=transform)\n",
    "dataset = NumpyArrayDataset(combined_array_scaled, transform=transform)\n",
    "print(combined_array_scaled.shape)\n",
    "\n",
    "# lazy, non-random split\n",
    "test_size = 0.2\n",
    "split_index = int(len(dataset) * (1 - test_size))\n",
    "train_dataset = dataset[:split_index]\n",
    "test_dataset = dataset[split_index:]\n",
    "#train_meta = meta_data_values[:split_index]\n",
    "#test_meta = meta_data_values[split_index:]\n",
    "#train_labels = meta_data_labels[:split_index]\n",
    "#test_labels = meta_data_labels[split_index:]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "valid_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "print(train_loader.dataset[0].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chosse device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def create_torch_model_CNN_HPO(trial):\n",
    "    N_conv_layers = trial.suggest_int('N_conv_layers', 1, 3)\n",
    "    N_dense_layers = trial.suggest_int('N_dense_layers', 1, 3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    num_classes = 3\n",
    "    class torch_CNN_HPO(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "\n",
    "            ### Flattening:\n",
    "            self.flatten = nn.Flatten(start_dim=0)\n",
    "\n",
    "            self.peram_to_optimize = []\n",
    "            ### dropout\n",
    "            self.dropout = nn.Dropout(dropout_rate, inplace=True)\n",
    "\n",
    "            self.compile_model()\n",
    "        \n",
    "        def create_CNN_layer(self, size_in, filters_in, layer_number):\n",
    "            filters_out = trial.suggest_int('filters_layer'+str(layer_number), 8, 64)\n",
    "            filter_size = trial.suggest_int('filter_size_layer'+str(layer_number), 3, 7)\n",
    "            stride_cnn = trial.suggest_int('stride_layer'+str(layer_number), 1, 3)\n",
    "            padding = trial.suggest_int('padding_layer'+str(layer_number), 1, 3)\n",
    "            pool_size = 3\n",
    "            pool_stride = 1\n",
    "            pool_padding = 1\n",
    "            cnn_layer = nn.Sequential(\n",
    "                nn.Conv2d(filters_in, filters_out, filter_size, stride=stride_cnn, padding=padding),  # 1x256x256 -> 32x128x128\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(pool_size, stride=pool_stride, padding=pool_padding)  # 64x64x64 -> 64x32x32\n",
    "            ).to(device)\n",
    "            size_out = (size_in - filter_size + 2*padding) // stride_cnn + 1\n",
    "            return cnn_layer, filters_out, size_out\n",
    "        \n",
    "        def create_liniar_layer(self, input_size, layer_number):\n",
    "            output_size = trial.suggest_int('dense_layer'+str(layer_number), 8, 128)\n",
    "            liniar_layer = nn.Sequential(\n",
    "                nn.Linear(input_size, output_size),\n",
    "                nn.ReLU(True)\n",
    "            ).to(device)\n",
    "            return liniar_layer, output_size\n",
    "        \n",
    "        def create_output_layer(self, input_size, output_size):\n",
    "            output_layer = nn.Sequential(\n",
    "                nn.Linear(input_size, output_size),\n",
    "                nn.ReLU()\n",
    "            ).to(device)\n",
    "            return output_layer\n",
    "        \n",
    "        def compile_model(self):\n",
    "            #print('Model compiled')\n",
    "            model_layers_cnn = []\n",
    "            model_layers_dense = []\n",
    "            size_in = 64\n",
    "            for i in range(N_conv_layers):\n",
    "                if i == 0:\n",
    "                    cnn_layer, filters_out, size_out = self.create_CNN_layer(size_in, 1, i)\n",
    "                else:\n",
    "                    cnn_layer, filters_out, size_out = self.create_CNN_layer(size_out, filters_out, i)\n",
    "                self.peram_to_optimize.append({'params': cnn_layer.parameters()})\n",
    "                model_layers_cnn.append(cnn_layer)\n",
    "\n",
    "            output_size = size_out ** 2 * filters_out\n",
    "            for i in range(N_dense_layers):\n",
    "                if i == 0:\n",
    "                    liniar_layer, output_size = self.create_liniar_layer(output_size, i)\n",
    "                else:\n",
    "                    liniar_layer, output_size = self.create_liniar_layer(output_size, i)\n",
    "                self.peram_to_optimize.append({'params': liniar_layer.parameters()})\n",
    "                model_layers_dense.append(liniar_layer)\n",
    "            \n",
    "            output_layer = self.create_output_layer(output_size + 4, num_classes)\n",
    "            self.peram_to_optimize.append({'params': output_layer.parameters()})\n",
    "        \n",
    "    \n",
    "            \n",
    "            def model_compiled_v2(x, meta):\n",
    "                for layer in model_layers_cnn:\n",
    "                    x = layer(x)\n",
    "                #print(x.shape)\n",
    "                x = self.flatten(x)\n",
    "                x = self.dropout(x)\n",
    "                for layer in model_layers_dense:\n",
    "                    x = layer(x)\n",
    "                y = torch.cat((x, meta), dim=0)\n",
    "                x = output_layer(y)\n",
    "                return x\n",
    "            self.model_compiled = model_compiled_v2\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            \n",
    "            meta = x[-5:-1]\n",
    "            label = x[-1]\n",
    "            x = x[:-5].unflatten(0, (1, 1, 64, 64))\n",
    "\n",
    "            x = self.model_compiled(x, meta)\n",
    "            #print(label.type(), x.type())\n",
    "            return x, label#.type(torch.cuda.ByteTensor)\n",
    "    return torch_CNN_HPO().to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_torch_model_CNN():\n",
    "    N_conv_layers = 1\n",
    "    N_dense_layers = 1\n",
    "    dropout_rate = 0.4\n",
    "    num_classes = 3\n",
    "    \n",
    "    \n",
    "\n",
    "    class torch_CNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "\n",
    "            ### Flattening:\n",
    "            self.flatten = nn.Flatten(start_dim=0)\n",
    "            self.peram_to_optimize = []\n",
    "\n",
    "            ### dropout\n",
    "            self.dropout = nn.Dropout(dropout_rate, inplace=True)\n",
    "\n",
    "            self.compile_model()\n",
    "\n",
    "        \n",
    "        def create_CNN_layer(self, size_in, filters_in):\n",
    "            filters_out = 8\n",
    "            filter_size = 3\n",
    "            stride_cnn = 1\n",
    "            padding = 1\n",
    "            pool_size = 3\n",
    "            pool_stride = 1\n",
    "            pool_padding = 1\n",
    "            cnn_layer = nn.Sequential(\n",
    "                nn.Conv2d(filters_in, filters_out, filter_size, stride=stride_cnn, padding=padding),  # 1x256x256 -> 32x128x128\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(pool_size, stride=pool_stride, padding=pool_padding)  # 64x64x64 -> 64x32x32\n",
    "            ).to(device)\n",
    "            size_out = (size_in - filter_size + 2*padding) // stride_cnn + 1\n",
    "            return cnn_layer, filters_out, size_out\n",
    "        \n",
    "        def create_liniar_layer(self, input_size):\n",
    "            output_size = 32\n",
    "            liniar_layer = nn.Sequential(\n",
    "                nn.Linear(input_size, output_size),\n",
    "                nn.ReLU(True)\n",
    "            ).to(device)\n",
    "            return liniar_layer, output_size\n",
    "        \n",
    "        def create_output_layer(self, input_size, output_size):\n",
    "            output_layer = nn.Sequential(\n",
    "                nn.Linear(input_size, output_size),\n",
    "                nn.ReLU()\n",
    "            ).to(device)\n",
    "            return output_layer\n",
    "        \n",
    "        \n",
    "        \n",
    "        def compile_model(self):\n",
    "            model_layers_cnn = []\n",
    "            model_layers_dense = []\n",
    "            size_in = 32\n",
    "            for i in range(N_conv_layers):\n",
    "                if i == 0:\n",
    "                    cnn_layer, filters_out, size_out = self.create_CNN_layer(size_in, 1)\n",
    "                else:\n",
    "                    cnn_layer, filters_out, size_out = self.create_CNN_layer(size_out, filters_out)\n",
    "\n",
    "                self.peram_to_optimize.append({'params': cnn_layer.parameters()})\n",
    "                model_layers_cnn.append(cnn_layer)\n",
    "\n",
    "            #output_size = size_out ** 2 * filters_out\n",
    "            output_size = filters_out\n",
    "            for i in range(N_dense_layers):\n",
    "                if i == 0:\n",
    "                    liniar_layer, output_size = self.create_liniar_layer(output_size)\n",
    "                else:\n",
    "                    liniar_layer, output_size = self.create_liniar_layer(output_size)\n",
    "                self.peram_to_optimize.append({'params': liniar_layer.parameters()})\n",
    "                model_layers_dense.append(liniar_layer)\n",
    "            \n",
    "            output_layer = self.create_output_layer(output_size + 4, num_classes)\n",
    "            self.peram_to_optimize.append({'params': output_layer.parameters()})\n",
    "            \n",
    "            \n",
    "            def model_compiled_v2(x, meta):\n",
    "                for layer in model_layers_cnn:\n",
    "                    x = layer(x)\n",
    "                   \n",
    "                #print(x.shape)\n",
    "                x = torch.mean(x, dim=3)\n",
    "                #print(x.shape)\n",
    "                x = torch.mean(x, dim=2)\n",
    "                #print(x.shape)\n",
    "                x = self.flatten(x)\n",
    "                x = self.dropout(x)\n",
    "                for layer in model_layers_dense:\n",
    "                    x = layer(x)\n",
    "                    \n",
    "                y = torch.cat((x, meta), dim=0)\n",
    "                x = output_layer(y)\n",
    "                \n",
    "                return x\n",
    "            self.model_compiled = model_compiled_v2\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            \n",
    "            meta = x[-5:-1]\n",
    "            label = x[-1]\n",
    "            x = x[:-5].unflatten(0, (1, 1, 64, 64))\n",
    "\n",
    "            x = self.model_compiled(x, meta)\n",
    "            return x, label#.type(torch.cuda.ByteTensor)\n",
    "    return torch_CNN().to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial, dataset_train, dataset_val, num_epochs=30):\n",
    "    # Build model and optimizer.\n",
    "    model = create_torch_model_CNN_HPO(trial)\n",
    "    learning_rate = trial.suggest_float(\"adam_learning_rate\", 1e-7, 1e-1, log=True)\n",
    "    torch.manual_seed(42)\n",
    "    peram_to_optimize = model.peram_to_optimize\n",
    "    \n",
    "    \n",
    "    optimizer = optim.Adam(peram_to_optimize, lr=learning_rate)\n",
    "    \n",
    "    model.train()\n",
    "    # Fit the model to the data\n",
    "    train_losses, valid_losses, train_accuracy, valid_accuracy = train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\n",
    "    #model.fit(x=X_train, y = Y_train, epochs=30, validation_data=(X_test, Y_test), verbose=0)\n",
    "    # Find the accuracy\n",
    "    #cce = CategoricalCrossentropy()\n",
    "    #accuracy = cce(Y_test, model(X_test))\n",
    "    #Return accuracy\n",
    "    return valid_losses[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(output, target):\n",
    "    try:\n",
    "        target = target.type(torch.cuda.ByteTensor)\n",
    "    except:\n",
    "        target = target.type(torch.ByteTensor)\n",
    "    #plt.plot(target.cpu().detach().numpy())\n",
    "    #plt.show()\n",
    "    #print(output, target)\n",
    "    #loss = F.cross_entropy(output, target)\n",
    "    \n",
    "\n",
    "    #cce = CategoricalCrossentropy()\n",
    "    #loss = cce(y_true, output.detach().numpy())\n",
    "\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')(output, target)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(dataset_train, model, optimizer, loss_function):\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for batch in dataset_train:\n",
    "        optimizer.zero_grad()\n",
    "        #print(next(model.parameters()).device, batch, model.device)\n",
    "        output, label_train = model(batch)\n",
    "        #print(label_train, output)\n",
    "        loss = loss_function(output, label_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        #output_detached = output.detach().numpy()\n",
    "        #label_train_detached = label_train.detach().numpy()\n",
    "        accuracy += 1#np.argmax(output_detached) == int(label_train_detached)#cce(label_train, output)\n",
    "    return running_loss / len(dataset_train), accuracy / len(dataset_train)\n",
    "\n",
    "def validate_epoch(dataset_val, model, loss_function):\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset_val:\n",
    "            output, label_val = model(batch)\n",
    "            loss = loss_function(output, label_val)\n",
    "            running_loss += loss.item()\n",
    "            #output_detached = output.detach().numpy()\n",
    "            #label_val_detached = label_val.detach().numpy()\n",
    "            accuracy += 1#np.argmax(output_detached) == int(label_val_detached)#cce(label_val, output)\n",
    "\n",
    "    return running_loss / len(dataset_val), accuracy / len(dataset_val)\n",
    "\n",
    "def train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function):\n",
    "    \n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracys = []\n",
    "    valid_losses = []\n",
    "    validate_accuracys = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_accuracy = train_epoch(dataset_train, model, optimizer, loss_function)\n",
    "        valid_loss, validate_accuracy = validate_epoch(dataset_val, model, loss_function)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracys.append(train_accuracy)\n",
    "        valid_losses.append(valid_loss)\n",
    "        validate_accuracys.append(validate_accuracy)\n",
    "        end_time = time.time()\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}, Train Accuracy: {train_accuracy}, Valid Accuracy: {validate_accuracy}, Duration: {end_time - start_time:.2f} sec\")\n",
    "    return train_losses, valid_losses, train_accuracys, validate_accuracys\n",
    "\n",
    "def plot_losses(train_losses, valid_losses, train_accuracys, validate_accuracys):\n",
    "    fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "    ax[0].plot(train_losses, label='Train Loss')\n",
    "    ax[0].plot(valid_losses, label='Valid Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[1].plot(train_accuracys, label='Train Accuracy')\n",
    "    ax[1].plot(validate_accuracys, label='Valid Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5514, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1., 0, 0])\n",
    "b = 1\n",
    "a = torch.tensor(a)\n",
    "b = torch.tensor(b)\n",
    "print(loss_function(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = train_loader.dataset[0]\n",
    "dataset_train = dataset_train.to(device)\n",
    "dataset_val = valid_loader.dataset[0]\n",
    "dataset_val = dataset_val.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30, Train Loss: 0.8804, Valid Loss: 0.6413, Duration: 11.45 sec\n",
      "Epoch: 2/30, Train Loss: 0.6006, Valid Loss: 0.5429, Duration: 11.34 sec\n",
      "Epoch: 3/30, Train Loss: 0.5604, Valid Loss: 0.5159, Duration: 12.16 sec\n",
      "Epoch: 4/30, Train Loss: 0.5361, Valid Loss: 0.5056, Duration: 11.77 sec\n",
      "Epoch: 5/30, Train Loss: 0.5216, Valid Loss: 0.5113, Duration: 12.49 sec\n",
      "Epoch: 6/30, Train Loss: 0.5168, Valid Loss: 0.4921, Duration: 11.44 sec\n",
      "Epoch: 7/30, Train Loss: 0.5136, Valid Loss: 0.4945, Duration: 11.85 sec\n",
      "Epoch: 8/30, Train Loss: 0.5086, Valid Loss: 0.4831, Duration: 12.50 sec\n",
      "Epoch: 9/30, Train Loss: 0.5040, Valid Loss: 0.4881, Duration: 12.21 sec\n",
      "Epoch: 10/30, Train Loss: 0.4974, Valid Loss: 0.4926, Duration: 12.05 sec\n",
      "Epoch: 11/30, Train Loss: 0.5014, Valid Loss: 0.4793, Duration: 11.42 sec\n",
      "Epoch: 12/30, Train Loss: 0.4998, Valid Loss: 0.4709, Duration: 11.31 sec\n",
      "Epoch: 13/30, Train Loss: 0.4982, Valid Loss: 0.4749, Duration: 11.38 sec\n",
      "Epoch: 14/30, Train Loss: 0.4935, Valid Loss: 0.4820, Duration: 11.22 sec\n",
      "Epoch: 15/30, Train Loss: 0.4925, Valid Loss: 0.4721, Duration: 11.37 sec\n",
      "Epoch: 16/30, Train Loss: 0.4862, Valid Loss: 0.4665, Duration: 11.26 sec\n",
      "Epoch: 17/30, Train Loss: 0.4900, Valid Loss: 0.4718, Duration: 11.21 sec\n",
      "Epoch: 18/30, Train Loss: 0.4872, Valid Loss: 0.4666, Duration: 11.19 sec\n",
      "Epoch: 19/30, Train Loss: 0.4843, Valid Loss: 0.4551, Duration: 11.25 sec\n",
      "Epoch: 20/30, Train Loss: 0.4788, Valid Loss: 0.4683, Duration: 11.25 sec\n",
      "Epoch: 21/30, Train Loss: 0.4828, Valid Loss: 0.4599, Duration: 11.30 sec\n",
      "Epoch: 22/30, Train Loss: 0.4777, Valid Loss: 0.4721, Duration: 11.29 sec\n",
      "Epoch: 23/30, Train Loss: 0.4834, Valid Loss: 0.4599, Duration: 11.26 sec\n",
      "Epoch: 24/30, Train Loss: 0.4786, Valid Loss: 0.4569, Duration: 11.29 sec\n",
      "Epoch: 25/30, Train Loss: 0.4790, Valid Loss: 0.4552, Duration: 11.23 sec\n",
      "Epoch: 26/30, Train Loss: 0.4692, Valid Loss: 0.4605, Duration: 11.24 sec\n",
      "Epoch: 27/30, Train Loss: 0.4715, Valid Loss: 0.4530, Duration: 11.22 sec\n",
      "Epoch: 28/30, Train Loss: 0.4754, Valid Loss: 0.4504, Duration: 11.29 sec\n",
      "Epoch: 29/30, Train Loss: 0.4720, Valid Loss: 0.4567, Duration: 11.22 sec\n",
      "Epoch: 30/30, Train Loss: 0.4706, Valid Loss: 0.4517, Duration: 11.32 sec\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "model = create_torch_model_CNN()\n",
    "\n",
    "learning_rate = 0.001\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#print(peram_to_optimize)\n",
    "peram_to_optimize = model.peram_to_optimize\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(peram_to_optimize, lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "train_losses, valid_losses, train_accuracys, validate_accuracys = train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(train_losses, valid_losses, train_accuracys, validate_accuracys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-10 16:41:31,857] A new study created in memory with name: no-name-3c243ae8-efb7-4a33-bbae-0ac9f6607adb\n",
      "[W 2024-06-10 16:43:35,286] Trial 0 failed with parameters: {'N_conv_layers': 2, 'N_dense_layers': 2, 'dropout_rate': 0.1962080324308098, 'filters_layer0': 44, 'filter_size_layer0': 4, 'stride_layer0': 1, 'padding_layer0': 1, 'filters_layer1': 39, 'filter_size_layer1': 7, 'stride_layer1': 1, 'padding_layer1': 2, 'dense_layer0': 127, 'dense_layer1': 39, 'adam_learning_rate': 0.01494901997245282} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sk0rt3/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9417/2604080421.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, dataset_train, dataset_val, num_epochs), n_trials=30)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9417/2858275657.py\", line 235, in objective\n",
      "    train_losses, valid_losses, train_accuracy, valid_accuracy = train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9417/2858275657.py\", line 311, in train_model\n",
      "    train_loss, train_accuracy = train_epoch(dataset_train, model, optimizer, loss_function)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9417/2858275657.py\", line 278, in train_epoch\n",
      "    loss.backward()\n",
      "  File \"/home/sk0rt3/anaconda3/lib/python3.11/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/sk0rt3/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-10 16:43:35,287] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, dataset_train, dataset_val, num_epochs), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[1;32m     63\u001b[0m             study,\n\u001b[1;32m     64\u001b[0m             func,\n\u001b[1;32m     65\u001b[0m             n_trials,\n\u001b[1;32m     66\u001b[0m             timeout,\n\u001b[1;32m     67\u001b[0m             catch,\n\u001b[1;32m     68\u001b[0m             callbacks,\n\u001b[1;32m     69\u001b[0m             gc_after_trial,\n\u001b[1;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, dataset_train, dataset_val, num_epochs), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 235\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, dataset_train, dataset_val, num_epochs)\u001b[0m\n\u001b[1;32m    233\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Fit the model to the data\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m train_losses, valid_losses, train_accuracy, valid_accuracy \u001b[38;5;241m=\u001b[39m train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m#model.fit(x=X_train, y = Y_train, epochs=30, validation_data=(X_test, Y_test), verbose=0)\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Find the accuracy\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m#cce = CategoricalCrossentropy()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m#accuracy = cce(Y_test, model(X_test))\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m#Return accuracy\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m valid_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[19], line 311\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    310\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 311\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m train_epoch(dataset_train, model, optimizer, loss_function)\n\u001b[1;32m    312\u001b[0m     valid_loss, validate_accuracy \u001b[38;5;241m=\u001b[39m validate_epoch(dataset_val, model, loss_function)\n\u001b[1;32m    313\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[19], line 278\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(dataset_train, model, optimizer, loss_function)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m#print(label_train, output)\u001b[39;00m\n\u001b[1;32m    277\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(output, label_train)\n\u001b[0;32m--> 278\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    279\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m#print(loss.item())\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "num_epochs = 10\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, dataset_train, dataset_val, num_epochs), n_trials=30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15162\n"
     ]
    }
   ],
   "source": [
    "print(42*19*19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk0rt3/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def test_func(model, dataset):\n",
    "    output = np.zeros(len(dataset))\n",
    "    label = np.zeros(len(dataset))\n",
    "    for batch in dataset:\n",
    "        model(batch)\n",
    "        \n",
    "for i in range(10):\n",
    "    test_func(model, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu False\n",
      "torch.cuda.ByteTensor torch.FloatTensor\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     24\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mnext\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice, dataset_train\u001b[38;5;241m.\u001b[39mis_cuda)\n\u001b[0;32m---> 31\u001b[0m train_losses, valid_losses \u001b[38;5;241m=\u001b[39m train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\n\u001b[1;32m     33\u001b[0m plot_losses(train_losses, valid_losses)\n",
      "Cell \u001b[0;32mIn[7], line 168\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    167\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 168\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(dataset_train, model, optimizer, loss_function)\n\u001b[1;32m    169\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m validate_epoch(dataset_val, model, loss_function)\n\u001b[1;32m    170\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[7], line 146\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(dataset_train, model, optimizer, loss_function)\u001b[0m\n\u001b[1;32m    144\u001b[0m output, label_train \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(label_train\u001b[38;5;241m.\u001b[39mtype(), output\u001b[38;5;241m.\u001b[39mtype())\n\u001b[0;32m--> 146\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(output, label_train)\n\u001b[1;32m    147\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    148\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[7], line 131\u001b[0m, in \u001b[0;36mloss_function\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_function\u001b[39m(output, target):\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, target)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)"
     ]
    }
   ],
   "source": [
    "model = create_torch_model_CNN(3).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "dataset_train = train_loader.dataset[0]\n",
    "dataset_val = valid_loader.dataset[0]\n",
    "\n",
    "\n",
    "dataset_train = dataset_train.to(device)\n",
    "dataset_val = dataset_val.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "torch.manual_seed(42)\n",
    "peram_to_optimize = model.parameters()\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(peram_to_optimize, lr=learning_rate)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "print(next(model.parameters()).device, dataset_train.is_cuda)\n",
    "\n",
    "\n",
    "train_losses, valid_losses = train_model(model, num_epochs, dataset_train, dataset_val, optimizer, loss_function)\n",
    "\n",
    "plot_losses(train_losses, valid_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
