{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "\n",
    "# Keras documentation can be found on keras.io:\n",
    "import keras\n",
    "# manual link to data:  http://yann.lecun.com/exdb/mnist/\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jens csv kode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_pad_csvs(folder_path):\n",
    "    # List all CSV files in the given folder\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    csv_files_sorted = np.sort(np.array(csv_files))\n",
    "    #print(csv_files_sorted)\n",
    "    # Initialize an empty list to store the data arrays\n",
    "    data_arrays = []\n",
    "\n",
    "    indecies = np.zeros_like(csv_files_sorted, dtype=int)\n",
    "    for i in range(len(csv_files_sorted)):\n",
    "        indecies[i] = int(csv_files_sorted[i][:-6])\n",
    "        #print(type(indecies[i]))\n",
    "    #print(csv_files_sorted, indecies)\n",
    "        \n",
    "    \n",
    "    # Iterate over the CSV files and read them into numpy arrays\n",
    "    for file in csv_files_sorted:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        data = pd.read_csv(file_path).values\n",
    "        data_arrays.append(data)\n",
    "    \n",
    "    # Find the maximum number of rows and columns among all CSV files\n",
    "    max_rows = max(array.shape[0] for array in data_arrays)\n",
    "    max_cols = max(array.shape[1] for array in data_arrays)\n",
    "    \n",
    "    # Find the index of the largest array (by number of elements)\n",
    "    largest_array_index = max(range(len(data_arrays)), key=lambda i: data_arrays[i].shape[0] * data_arrays[i].shape[1])\n",
    "    \n",
    "    print(f\"Index of the largest initial array: {largest_array_index}\")\n",
    "    \n",
    "    # Initialize a list to store padded arrays\n",
    "    padded_arrays = np.zeros((max_rows, max_cols))\n",
    "    center = max(int(max_rows / 2), int(max_cols / 2))\n",
    "    max_size = 64\n",
    "    combined_array = np.zeros((len(data_arrays), max_size, max_size))\n",
    "    # Pad each array with zeros to match the maximum size\n",
    "    nr = 0\n",
    "    for array in data_arrays:\n",
    "        #print(array.shape)\n",
    "        #print(center - int(np.floor(array.shape[0] / 2)), center + int(np.ceil(array.shape[1] / 2)))\n",
    "        padded_array = np.zeros((max_rows, max_cols)) + 4000\n",
    "        #print(padded_array[center - int(np.floor(array.shape[0] / 2)) :center + int(np.ceil(array.shape[0]/2)),\n",
    "                     #center - int(np.floor(array.shape[1] / 2)) :center + int(np.ceil(array.shape[1]/2))])\n",
    "        padded_array[center - int(np.floor(array.shape[0] / 2)) :center + int(np.ceil(array.shape[0]/2)),\n",
    "                     center - int(np.floor(array.shape[1] / 2)) :center + int(np.ceil(array.shape[1]/2))] = array\n",
    "        combined_array[nr] = padded_array[center - int(max_size/2): center + int(max_size/2), center - int(max_size/2): center + int(max_size/2)]\n",
    "        #combined_array = np.concatenate((combined_array, np.array([padded_arrays])), axis=0)\n",
    "        #padded_arrays.append(padded_array)\n",
    "        nr += 1\n",
    "    \n",
    "\n",
    "    # Stack all padded arrays along a new dimension to create the final array\n",
    "    #combined_array = np.stack(padded_arrays, axis=0)\n",
    "    \n",
    "    \n",
    "    return combined_array, indecies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(['123456', '12345', '1235312'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the largest initial array: 3929\n",
      "31 31\n"
     ]
    }
   ],
   "source": [
    "data_raw, index = import_and_pad_csvs('clusters_colour_rotations/')\n",
    "labels_raw = [np.load('./labels/'+x) for x in os.listdir('./labels/') if x.endswith('.npy')]\n",
    "print(len(labels_raw[8][0]), len(labels_raw[8][1]))\n",
    "\n",
    "#labels_raw_sorted = np.sort(np.array(labels_raw))\n",
    "label = []\n",
    "ind = []\n",
    "for value in labels_raw:\n",
    "    label.append(value[1].tolist())\n",
    "    ind.append(value[0].tolist())\n",
    "    #print(len(value[1].tolist()), len(value[0].tolist()))\n",
    "label = [item for sublist in label for item in sublist]\n",
    "ind = [item for sublist in ind for item in sublist]\n",
    "ind_sort_arg = np.argsort(np.repeat(ind, 8))\n",
    "#mask = [index != ind]\n",
    "#print(print(index, ind))\n",
    "#plt.plot(index - ind)\n",
    "#plt.show()\n",
    "\n",
    "#index_remove = np.array([31, 74, 116, 165, 170, 193, 214, 280, 314, 401, 413, 470, 499])\n",
    "#label = np.delete(label, index_remove)\n",
    "\n",
    "label = np.repeat(label, 8)\n",
    "#print(len(label)*8)\n",
    "#print(data_raw.shape)\n",
    "\n",
    "\n",
    "label_sorted = label[ind_sort_arg]\n",
    "\n",
    "# Remove all reading erros, multiple objects, and others.\n",
    "data_raw = data_raw[(label_sorted != 4) & (label_sorted != 0)]\n",
    "label_sorted = label_sorted[(label_sorted != 4) & (label_sorted != 0)] - 1\n",
    "\n",
    "#print(data_raw.shape)\n",
    "# the data, split between train and testval sets\n",
    "train_images, testval_images, train_labels, testval_labels = train_test_split(data_raw, label_sorted, test_size=0.3, random_state=13052020)\n",
    "\n",
    "# further split testval set into specific test and validation set\n",
    "# the test set is NOT used during any part but inference\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(testval_images, testval_labels, test_size=0.2, random_state=13052020)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normelize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, RobustScaler\n",
    "\n",
    "# explicitly illustrating standardization\n",
    "def standardizeimg(img, mu, sigma):\n",
    "    return (img-mu)/(sigma).astype(np.float32)\n",
    "\n",
    "# save for scaling test data\n",
    "mu_train = np.mean(train_images)\n",
    "sigma_train = np.std(train_images)\n",
    "\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#scaler = QuantileTransformer()\n",
    "scaler = RobustScaler()\n",
    "#sorted_images = np.sort(train_images.reshape(-1, 1))\n",
    "#scaler.fit(sorted_images)\n",
    "scaler.fit(train_images.reshape(-1, 1))\n",
    "train_images = scaler.transform(train_images.reshape(-1, 1)).reshape(train_images.shape)\n",
    "val_images = scaler.transform(val_images.reshape(-1, 1)).reshape(val_images.shape)\n",
    "\n",
    "plt.hist(train_images.flatten(), bins=100, range=(0.01, 1))\n",
    "plt.show()\n",
    "# Standardize pixel distribution to have zero mean and unit variance\n",
    "#train_images = standardizeimg(img=train_images, mu=mu_train, sigma=sigma_train)\n",
    "#val_images = standardizeimg(img=val_images, mu=np.mean(val_images), sigma=np.std(val_images))\n",
    "# Alternative: quantile normalization\n",
    "# train_images = quantile_transform(train_images, output_distribution='normal', copy=True)\n",
    "# val_images = quantile_transform(val_images, output_distribution='normal', copy=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# adapt to format required by tensorflow; Using channels_last --> (n_samples, img_rows, img_cols, n_channels)\n",
    "img_rows, img_cols = 64, 64 # input image dimensions\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "val_images = val_images.reshape(val_images.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# convert class vectors to binary class matrices - one hot encoding\n",
    "num_classes = 3 # number of classes\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "val_labels = keras.utils.to_categorical(val_labels, num_classes)\n",
    "\n",
    "# avoid using statistics intrinsic to test data to ensure unbiased estimate of real model performance\n",
    "test_images = standardizeimg(img=test_images, mu=mu_train, sigma=sigma_train)\n",
    "# test_images = quantile_transform(test_images, output_distribution='normal', copy=True)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk0rt3/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m2,097,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,116,483</span> (8.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,116,483\u001b[0m (8.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,116,483</span> (8.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,116,483\u001b[0m (8.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compile_CNN_model(model_type=Sequential(), layer_types=[Conv2D, MaxPooling2D, Flatten, Dropout, Dense], hyperperams_list=np.zeros((7,3)), img_rows=28, img_cols=28, num_classes=10):\n",
    "    model = model_type  # Network model type\n",
    "\n",
    "    N_layers = len(layer_types)\n",
    "    layers = np.array([])\n",
    "    for i in range(layer_types):\n",
    "        if layer_types[i] == 0:\n",
    "            layers = np.append(layers, Conv2D)\n",
    "            hyp_peram = {'filters': hyperperams_list[i, 0], 'kernel_size': hyperperams_list[i, 1], 'strides': hyperperams_list[i, 2], 'activation': 'relu', 'input_shape': (img_rows, img_cols, 1)}\n",
    "            hyperperams = np.append(hyperperams, hyp_peram)\n",
    "\n",
    "        if layer_types[i] == 1:\n",
    "            layers = np.append(layers, MaxPooling2D)\n",
    "            hyp_peram = {'pool_size': hyperperams_list[i, 0], 'strides': hyperperams_list[i, 1]}\n",
    "            hyperperams = np.append(hyperperams, hyp_peram)\n",
    "        if layer_types[i] == 2:\n",
    "            layers = np.append(layers, Flatten)\n",
    "            hyp_peram = {}\n",
    "            hyperperams = np.append(hyperperams, hyp_peram)\n",
    "        if layer_types[i] == 3:\n",
    "            layers = np.append(layers, Dropout)\n",
    "            hyp_peram = {'rate': hyperperams_list[i, 0]}\n",
    "            hyperperams = np.append(hyperperams, hyp_peram)\n",
    "\n",
    "        if layer_types[i] == 4:\n",
    "            layers = np.append(layers, Dense)\n",
    "            hyp_peram = {'units': hyperperams_list[i, 0], 'activation': 'relu'}\n",
    "            \n",
    "    \n",
    "    for i in range(N_layers):\n",
    "        model.add(layers[i](**layer_hyperperams[i]))\n",
    "\n",
    "    \n",
    "    # specify optimization strategy and metric used for monitoring during training\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()  # Network type is Sequential\n",
    "\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(Dropout(rate=0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# specify optimization strategy and metric used for monitoring during training\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 283ms/step - categorical_accuracy: 0.2591 - loss: 161.3145 - val_categorical_accuracy: 0.2106 - val_loss: 109.1379\n",
      "Epoch 2/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - categorical_accuracy: 0.2677 - loss: 146.7508 - val_categorical_accuracy: 0.2291 - val_loss: 99.2579\n",
      "Epoch 3/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - categorical_accuracy: 0.2901 - loss: 136.8194 - val_categorical_accuracy: 0.2556 - val_loss: 91.0016\n",
      "Epoch 4/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - categorical_accuracy: 0.2955 - loss: 127.0667 - val_categorical_accuracy: 0.2927 - val_loss: 83.8409\n",
      "Epoch 5/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step - categorical_accuracy: 0.3229 - loss: 120.7425 - val_categorical_accuracy: 0.3179 - val_loss: 77.9708\n",
      "Epoch 6/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252ms/step - categorical_accuracy: 0.3323 - loss: 119.0967 - val_categorical_accuracy: 0.3364 - val_loss: 72.6828\n",
      "Epoch 7/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.3572 - loss: 112.2582 - val_categorical_accuracy: 0.3563 - val_loss: 67.9186\n",
      "Epoch 8/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.3852 - loss: 96.9364 - val_categorical_accuracy: 0.3801 - val_loss: 63.9057\n",
      "Epoch 9/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.3772 - loss: 96.7874 - val_categorical_accuracy: 0.4093 - val_loss: 60.4066\n",
      "Epoch 10/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.4109 - loss: 85.6321 - val_categorical_accuracy: 0.4238 - val_loss: 57.3989\n",
      "Epoch 11/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260ms/step - categorical_accuracy: 0.4168 - loss: 88.3916 - val_categorical_accuracy: 0.4543 - val_loss: 54.6076\n",
      "Epoch 12/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258ms/step - categorical_accuracy: 0.4251 - loss: 91.2895 - val_categorical_accuracy: 0.4702 - val_loss: 52.3232\n",
      "Epoch 13/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257ms/step - categorical_accuracy: 0.4650 - loss: 80.9936 - val_categorical_accuracy: 0.4887 - val_loss: 50.3997\n",
      "Epoch 14/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - categorical_accuracy: 0.4920 - loss: 76.9603 - val_categorical_accuracy: 0.5099 - val_loss: 48.7264\n",
      "Epoch 15/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - categorical_accuracy: 0.4970 - loss: 71.9447 - val_categorical_accuracy: 0.5364 - val_loss: 47.2277\n",
      "Epoch 16/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 263ms/step - categorical_accuracy: 0.4928 - loss: 77.3567 - val_categorical_accuracy: 0.5563 - val_loss: 45.9220\n",
      "Epoch 17/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257ms/step - categorical_accuracy: 0.5025 - loss: 72.3798 - val_categorical_accuracy: 0.5841 - val_loss: 44.8090\n",
      "Epoch 18/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 265ms/step - categorical_accuracy: 0.5300 - loss: 66.1995 - val_categorical_accuracy: 0.6040 - val_loss: 43.8046\n",
      "Epoch 19/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.5514 - loss: 68.3436 - val_categorical_accuracy: 0.6318 - val_loss: 43.0831\n",
      "Epoch 20/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258ms/step - categorical_accuracy: 0.5464 - loss: 66.1600 - val_categorical_accuracy: 0.6437 - val_loss: 42.3999\n",
      "Epoch 21/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - categorical_accuracy: 0.5408 - loss: 65.3187 - val_categorical_accuracy: 0.6583 - val_loss: 41.7580\n",
      "Epoch 22/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252ms/step - categorical_accuracy: 0.5850 - loss: 60.5887 - val_categorical_accuracy: 0.6808 - val_loss: 41.1169\n",
      "Epoch 23/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 251ms/step - categorical_accuracy: 0.5834 - loss: 60.1535 - val_categorical_accuracy: 0.6967 - val_loss: 40.5404\n",
      "Epoch 24/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252ms/step - categorical_accuracy: 0.5847 - loss: 62.4757 - val_categorical_accuracy: 0.7113 - val_loss: 40.0818\n",
      "Epoch 25/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256ms/step - categorical_accuracy: 0.5839 - loss: 59.7595 - val_categorical_accuracy: 0.7219 - val_loss: 39.6839\n",
      "Epoch 26/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.5856 - loss: 55.6822 - val_categorical_accuracy: 0.7351 - val_loss: 39.2077\n",
      "Epoch 27/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 247ms/step - categorical_accuracy: 0.6122 - loss: 53.3637 - val_categorical_accuracy: 0.7483 - val_loss: 38.8412\n",
      "Epoch 28/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - categorical_accuracy: 0.5884 - loss: 58.2404 - val_categorical_accuracy: 0.7563 - val_loss: 38.4710\n",
      "Epoch 29/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - categorical_accuracy: 0.6314 - loss: 47.5821 - val_categorical_accuracy: 0.7642 - val_loss: 38.0454\n",
      "Epoch 30/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - categorical_accuracy: 0.6141 - loss: 57.1389 - val_categorical_accuracy: 0.7656 - val_loss: 37.8556\n",
      "Epoch 31/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.6432 - loss: 50.2543 - val_categorical_accuracy: 0.7722 - val_loss: 37.6920\n",
      "Epoch 32/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - categorical_accuracy: 0.6422 - loss: 50.8421 - val_categorical_accuracy: 0.7762 - val_loss: 37.3128\n",
      "Epoch 33/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - categorical_accuracy: 0.6519 - loss: 55.4619 - val_categorical_accuracy: 0.7748 - val_loss: 37.0344\n",
      "Epoch 34/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 243ms/step - categorical_accuracy: 0.6522 - loss: 53.2703 - val_categorical_accuracy: 0.7762 - val_loss: 36.7956\n",
      "Epoch 35/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - categorical_accuracy: 0.6306 - loss: 55.3450 - val_categorical_accuracy: 0.7841 - val_loss: 36.6381\n",
      "Epoch 36/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - categorical_accuracy: 0.6462 - loss: 53.2723 - val_categorical_accuracy: 0.7854 - val_loss: 36.3304\n",
      "Epoch 37/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - categorical_accuracy: 0.6482 - loss: 47.6534 - val_categorical_accuracy: 0.7881 - val_loss: 36.2236\n",
      "Epoch 38/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255ms/step - categorical_accuracy: 0.6552 - loss: 47.6317 - val_categorical_accuracy: 0.7907 - val_loss: 35.9761\n",
      "Epoch 39/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - categorical_accuracy: 0.6836 - loss: 44.8195 - val_categorical_accuracy: 0.7921 - val_loss: 35.7021\n",
      "Epoch 40/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.6677 - loss: 51.3818 - val_categorical_accuracy: 0.7947 - val_loss: 35.4392\n",
      "Epoch 41/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - categorical_accuracy: 0.6625 - loss: 44.7833 - val_categorical_accuracy: 0.7987 - val_loss: 35.3360\n",
      "Epoch 42/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - categorical_accuracy: 0.6789 - loss: 48.9320 - val_categorical_accuracy: 0.8026 - val_loss: 35.0312\n",
      "Epoch 43/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.6711 - loss: 50.3542 - val_categorical_accuracy: 0.8026 - val_loss: 34.8371\n",
      "Epoch 44/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.6758 - loss: 48.7329 - val_categorical_accuracy: 0.8040 - val_loss: 34.7002\n",
      "Epoch 45/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - categorical_accuracy: 0.6701 - loss: 47.6477 - val_categorical_accuracy: 0.8066 - val_loss: 34.6558\n",
      "Epoch 46/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - categorical_accuracy: 0.6933 - loss: 44.5916 - val_categorical_accuracy: 0.8106 - val_loss: 34.5986\n",
      "Epoch 47/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - categorical_accuracy: 0.6984 - loss: 42.3240 - val_categorical_accuracy: 0.8106 - val_loss: 34.3587\n",
      "Epoch 48/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - categorical_accuracy: 0.6986 - loss: 42.9655 - val_categorical_accuracy: 0.8106 - val_loss: 34.0891\n",
      "Epoch 49/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - categorical_accuracy: 0.7122 - loss: 41.3694 - val_categorical_accuracy: 0.8119 - val_loss: 33.7310\n",
      "Epoch 50/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - categorical_accuracy: 0.6984 - loss: 42.6554 - val_categorical_accuracy: 0.8119 - val_loss: 33.7253\n",
      "Epoch 51/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.7135 - loss: 46.3336 - val_categorical_accuracy: 0.8159 - val_loss: 33.6023\n",
      "Epoch 52/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.7267 - loss: 42.1717 - val_categorical_accuracy: 0.8172 - val_loss: 33.4793\n",
      "Epoch 53/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - categorical_accuracy: 0.7024 - loss: 45.8003 - val_categorical_accuracy: 0.8199 - val_loss: 33.2464\n",
      "Epoch 54/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - categorical_accuracy: 0.7154 - loss: 40.4791 - val_categorical_accuracy: 0.8199 - val_loss: 32.8478\n",
      "Epoch 55/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.7078 - loss: 44.2049 - val_categorical_accuracy: 0.8212 - val_loss: 32.7439\n",
      "Epoch 56/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.7112 - loss: 39.7329 - val_categorical_accuracy: 0.8238 - val_loss: 32.6413\n",
      "Epoch 57/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - categorical_accuracy: 0.7249 - loss: 37.8602 - val_categorical_accuracy: 0.8252 - val_loss: 32.4734\n",
      "Epoch 58/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - categorical_accuracy: 0.7349 - loss: 41.6436 - val_categorical_accuracy: 0.8278 - val_loss: 32.1636\n",
      "Epoch 59/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - categorical_accuracy: 0.7296 - loss: 38.4101 - val_categorical_accuracy: 0.8278 - val_loss: 31.9415\n",
      "Epoch 60/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - categorical_accuracy: 0.7100 - loss: 43.6563 - val_categorical_accuracy: 0.8278 - val_loss: 31.8916\n",
      "Epoch 61/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.7335 - loss: 36.7923 - val_categorical_accuracy: 0.8265 - val_loss: 31.6404\n",
      "Epoch 62/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 251ms/step - categorical_accuracy: 0.7264 - loss: 38.4171 - val_categorical_accuracy: 0.8305 - val_loss: 31.3717\n",
      "Epoch 63/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.7289 - loss: 39.7369 - val_categorical_accuracy: 0.8305 - val_loss: 31.0390\n",
      "Epoch 64/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.7342 - loss: 39.4930 - val_categorical_accuracy: 0.8305 - val_loss: 30.6910\n",
      "Epoch 65/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.7516 - loss: 37.4201 - val_categorical_accuracy: 0.8318 - val_loss: 30.4478\n",
      "Epoch 66/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.7519 - loss: 34.0612 - val_categorical_accuracy: 0.8318 - val_loss: 30.3817\n",
      "Epoch 67/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.7534 - loss: 37.5642 - val_categorical_accuracy: 0.8318 - val_loss: 30.3331\n",
      "Epoch 68/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.7527 - loss: 36.0536 - val_categorical_accuracy: 0.8331 - val_loss: 29.9381\n",
      "Epoch 69/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - categorical_accuracy: 0.7374 - loss: 40.5318 - val_categorical_accuracy: 0.8331 - val_loss: 30.0228\n",
      "Epoch 70/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 267ms/step - categorical_accuracy: 0.7528 - loss: 35.2445 - val_categorical_accuracy: 0.8331 - val_loss: 29.8535\n",
      "Epoch 71/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 269ms/step - categorical_accuracy: 0.7480 - loss: 34.3485 - val_categorical_accuracy: 0.8318 - val_loss: 29.5692\n",
      "Epoch 72/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - categorical_accuracy: 0.7490 - loss: 36.8963 - val_categorical_accuracy: 0.8344 - val_loss: 29.3740\n",
      "Epoch 73/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - categorical_accuracy: 0.7712 - loss: 34.2286 - val_categorical_accuracy: 0.8331 - val_loss: 29.2438\n",
      "Epoch 74/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.7665 - loss: 33.5251 - val_categorical_accuracy: 0.8331 - val_loss: 29.1007\n",
      "Epoch 75/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.7405 - loss: 37.8277 - val_categorical_accuracy: 0.8344 - val_loss: 28.9953\n",
      "Epoch 76/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - categorical_accuracy: 0.7650 - loss: 36.9292 - val_categorical_accuracy: 0.8384 - val_loss: 29.0110\n",
      "Epoch 77/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.7405 - loss: 37.4605 - val_categorical_accuracy: 0.8384 - val_loss: 28.9481\n",
      "Epoch 78/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - categorical_accuracy: 0.7641 - loss: 35.8517 - val_categorical_accuracy: 0.8384 - val_loss: 28.7812\n",
      "Epoch 79/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 251ms/step - categorical_accuracy: 0.7615 - loss: 34.9336 - val_categorical_accuracy: 0.8384 - val_loss: 28.6791\n",
      "Epoch 80/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - categorical_accuracy: 0.7503 - loss: 36.7387 - val_categorical_accuracy: 0.8384 - val_loss: 28.6134\n",
      "Epoch 81/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.7565 - loss: 36.9230 - val_categorical_accuracy: 0.8384 - val_loss: 28.4183\n",
      "Epoch 82/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - categorical_accuracy: 0.7660 - loss: 34.5790 - val_categorical_accuracy: 0.8384 - val_loss: 28.2851\n",
      "Epoch 83/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 247ms/step - categorical_accuracy: 0.7465 - loss: 32.6949 - val_categorical_accuracy: 0.8397 - val_loss: 28.2959\n",
      "Epoch 84/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - categorical_accuracy: 0.7555 - loss: 33.0669 - val_categorical_accuracy: 0.8397 - val_loss: 28.0854\n",
      "Epoch 85/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - categorical_accuracy: 0.7600 - loss: 34.5742 - val_categorical_accuracy: 0.8397 - val_loss: 28.0581\n",
      "Epoch 86/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - categorical_accuracy: 0.7580 - loss: 33.6325 - val_categorical_accuracy: 0.8397 - val_loss: 28.0146\n",
      "Epoch 87/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.7838 - loss: 30.8828 - val_categorical_accuracy: 0.8384 - val_loss: 27.6678\n",
      "Epoch 88/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - categorical_accuracy: 0.7627 - loss: 37.0922 - val_categorical_accuracy: 0.8384 - val_loss: 27.4690\n",
      "Epoch 89/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - categorical_accuracy: 0.7912 - loss: 28.4449 - val_categorical_accuracy: 0.8397 - val_loss: 27.2645\n",
      "Epoch 90/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - categorical_accuracy: 0.7747 - loss: 31.6008 - val_categorical_accuracy: 0.8397 - val_loss: 27.3011\n",
      "Epoch 91/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 247ms/step - categorical_accuracy: 0.7613 - loss: 31.8811 - val_categorical_accuracy: 0.8397 - val_loss: 27.2637\n",
      "Epoch 92/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.7787 - loss: 35.3371 - val_categorical_accuracy: 0.8411 - val_loss: 27.0014\n",
      "Epoch 93/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.7795 - loss: 32.6903 - val_categorical_accuracy: 0.8411 - val_loss: 26.8979\n",
      "Epoch 94/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.7821 - loss: 29.2504 - val_categorical_accuracy: 0.8411 - val_loss: 26.6618\n",
      "Epoch 95/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - categorical_accuracy: 0.7815 - loss: 30.5363 - val_categorical_accuracy: 0.8411 - val_loss: 26.3017\n",
      "Epoch 96/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - categorical_accuracy: 0.7946 - loss: 29.0860 - val_categorical_accuracy: 0.8411 - val_loss: 26.2763\n",
      "Epoch 97/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258ms/step - categorical_accuracy: 0.7867 - loss: 31.5258 - val_categorical_accuracy: 0.8424 - val_loss: 26.0740\n",
      "Epoch 98/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - categorical_accuracy: 0.7654 - loss: 36.4806 - val_categorical_accuracy: 0.8437 - val_loss: 25.9378\n",
      "Epoch 99/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - categorical_accuracy: 0.7762 - loss: 33.0119 - val_categorical_accuracy: 0.8411 - val_loss: 25.7155\n",
      "Epoch 100/100\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - categorical_accuracy: 0.7779 - loss: 33.7196 - val_categorical_accuracy: 0.8424 - val_loss: 25.5174\n"
     ]
    }
   ],
   "source": [
    "# the history object will contain a record of loss and metric values during training\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[[0.50016767 0.12039484 0.3794375 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    layer_numbers = trial.suggest_int('layer_numbers', 1, 10)\n",
    "    peram = {'model_type': Sequential(),\n",
    "                'layer_types': [trail.sugeest_int('layer_types', 0, 4, layer_numbers) for i in range(layer_numbers)],\n",
    "                'hyperperams_list': np.zeros((7,3)),\n",
    "                'img_rows': 28,\n",
    "                'img_cols': 28,\n",
    "                'num_classes': 10\n",
    "                }\n",
    "        \n",
    "    \n",
    "\n",
    "def objective_exmaple(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 1),\n",
    "        'objective': 'binary:logistic'\n",
    "    }\n",
    "    bst = XGBClassifier(**param)\n",
    "    bst.fit(df_train_X_clf_final, df_train_Y_clf_final)\n",
    "    preds = bst.predict_proba(df_valid_X_clf_final)\n",
    "    log_log_clf_XGB = log_loss(df_valid_Y_clf_final, preds)\n",
    "    return log_log_clf_XGB\n",
    "\n",
    "study_example = optuna.create_study(direction='minimize')\n",
    "study_example.optimize(objective_example, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
